{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# PyTorchとOpenFLを用いたFederated Learningのチュートリアル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc32bf2-24e9-4f73-9220-12e1f9457235",
   "metadata": {},
   "source": [
    "（注）このチュートリアルは[公式サンプル](https://github.com/intel/openfl/blob/v1.5/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/pytorch_tinyimagenet.ipynb)を元ネタとして、より分かりやすくするために一部を編集しております。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe66355-8670-4023-ab31-3ff8370d9683",
   "metadata": {},
   "source": [
    "## ライブラリーのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895288d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.13.1\n",
    "!pip install torchvision==0.14.1\n",
    "!pip install setuptools>=65.5.1 # not directly required, pinned by Snyk to avoid a vulnerability\n",
    "!pip install wheel>=0.38.0 # not directly required, pinned by Snyk to avoid a vulnerability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bcd44-0bd5-4534-9a54-4a73beba2813",
   "metadata": {},
   "source": [
    "## ライブラリーのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "from copy import deepcopy\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88714c9-3be8-4abe-8625-c6113a4aa984",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c8b3f-7ef5-4d01-a4db-dc845f2b385a",
   "metadata": {},
   "source": [
    "## PyTorchベースのモデル学習スクリプト作成\n",
    "ただし、一部OpenFLのお作法に則り実装すべき個所（【OpenFL独自コード】という部分）がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49936a28-ff95-4874-96c0-48e7e38d6b1d",
   "metadata": {},
   "source": [
    "## データセットの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918faf40-b5ce-484f-b003-a63d70d4ef6a",
   "metadata": {},
   "source": [
    "通常のPyTorchプログラミングと同様にDatasetとデータ加工処理を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2a626-ca09-43fa-b572-e66a45ed2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = T.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "augmentation = T.RandomApply(\n",
    "    [T.RandomHorizontalFlip(),\n",
    "     T.RandomRotation(10),\n",
    "     T.RandomResizedCrop(64)], \n",
    "    p=.8\n",
    ")\n",
    "\n",
    "training_transform = T.Compose(\n",
    "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "     T.ToTensor(),\n",
    "     augmentation,\n",
    "     normalize]\n",
    ")\n",
    "\n",
    "valid_transform = T.Compose(\n",
    "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "     T.ToTensor(),\n",
    "     normalize]\n",
    ")\n",
    "\n",
    "class TransformedDataset(Dataset):\n",
    "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        \"\"\"Initialize Dataset.\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of dataset.\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "        label = self.target_transform(label) if self.target_transform else label\n",
    "        img = self.transform(img) if self.transform else img\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284cc6a-d599-49a0-8360-a587a51bd892",
   "metadata": {},
   "source": [
    "【OpenFL独自コード】\n",
    "OpenFLが提供するDataInterfaceクラスを継承して、下記サンプルのお作法通りに実装する。\n",
    "このクラスが本ソースコードと各コラボレーター上のShard Descriptorとのインターフェースになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01369e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNetDataset(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        self.train_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('train'),\n",
    "            transform=training_transform\n",
    "        )\n",
    "        self.valid_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('val'),\n",
    "            transform=valid_transform\n",
    "        )\n",
    "        \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        generator=torch.Generator()\n",
    "        generator.manual_seed(0)\n",
    "        return DataLoader(\n",
    "            self.train_set, batch_size=self.kwargs['train_bs'], shuffle=True, generator=generator\n",
    "            )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = TinyImageNetDataset(train_bs=64, valid_bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7295fc-e697-48b6-bec8-ecf7f497dcea",
   "metadata": {},
   "source": [
    "## モデルの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e478be-bbf0-45ee-b11f-ef6c72c1d80d",
   "metadata": {},
   "source": [
    "通常のPyTorchプログラミングと同様にモデルを定義する。本デモではTorchvisionのMobileNet V2をファインチューニングしていく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e25fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MobileNetV2 model\n",
    "\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(0)\n",
    "        super(Net, self).__init__()\n",
    "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.classifier[1] = torch.nn.Linear(in_features=1280, \\\n",
    "                        out_features=200, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward(x)\n",
    "        return x\n",
    "\n",
    "model_net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821af2e-7d7e-49f7-abc5-63a5e9179c6d",
   "metadata": {},
   "source": [
    "こちらも通常のPyTorchプログラミングと同様にOptimizerと損失関数を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79021778",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for param in model_net.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        \n",
    "optimizer_adam = optim.Adam(params_to_update, lr=1e-4)\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    \"\"\"Binary cross-entropy metric\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(input=output,target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807aab1e-2431-408f-bae9-f9257bbcc1cf",
   "metadata": {},
   "source": [
    "【OpenFL独自コード】OpenFLが提供するModelInterfaceクラスのインスタンスを作成し、モデルとOptimizerのインスタンスをセットする。\n",
    "このModelInterfaceによりモデルデータがコラボレーターに転送される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "model_interface = ModelInterface(model=model_net, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fe6cb-56fb-4015-93f3-0fd634538139",
   "metadata": {},
   "source": [
    "## 学習処理（Train）と検証処理（Validation）の定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151b1af-af0b-4e64-abad-143e751c3e73",
   "metadata": {},
   "source": [
    "【OpenFL独自コード】TrainとValの処理自体は通常のPyTorchのお作法で実装できるが、その関数をOpenFLのTaskInterfaceにタスクとして登録する必要がある。書き方は以下の通り、少し癖があるが慣れるしかない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9649385",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_interface = TaskInterface()\n",
    "\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@task_interface.add_kwargs(**{'some_parameter': 42})\n",
    "@task_interface.register_fl_task(model='net_model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(net_model, train_loader, optimizer, device, loss_fn=cross_entropy, some_parameter=None):\n",
    "    torch.manual_seed(0)\n",
    "    device='cpu'\n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    net_model.train()\n",
    "    net_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net_model(data)\n",
    "        loss = loss_fn(output=output, target=target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "\n",
    "@task_interface.register_fl_task(model='net_model', data_loader='val_loader', device='device')     \n",
    "def validate(net_model, val_loader, device):\n",
    "    torch.manual_seed(0)\n",
    "    device = torch.device('cpu')\n",
    "    net_model.eval()\n",
    "    net_model.to(device)\n",
    "    \n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "            output = net_model(data)\n",
    "            pred = output.argmax(dim=1,keepdim=True)\n",
    "            val_score += pred.eq(target).sum().cpu().numpy()\n",
    "            \n",
    "    return {'acc': val_score / total_samples,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da5d9a-11b8-4de0-a09e-a9da1c06e178",
   "metadata": {},
   "source": [
    "ここまででモデルの学習に関連するPyTorchの実装は完了です。通常のPyTorchプログラミングに加えてOpenFL独自のコードを多少加える必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9542cb-902c-4cff-bdf0-8977a3abf1dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## 連合（Federation）へ接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'api'\n",
    "director_node_fqdn = 'localhost'\n",
    "\n",
    "# 1) TLS無しで接続（検証、PoC向け）\n",
    "federation = Federation(\n",
    "    client_id=client_id, \n",
    "    director_node_fqdn=director_node_fqdn, \n",
    "    director_port='50051', \n",
    "    tls=False)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# please use the same identificator that was used in signed certificate\n",
    "# 2) mTLS有りで接続（本番環境向け）\n",
    "# ユーザーがmTLSを有効にする場合、CAルートチェーンと署名されたキーペアをフェデレーションインターフェースに提供する必要があります。\n",
    "# cert_dir = 'cert'\n",
    "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
    "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
    "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
    "# federation = Federation(\n",
    "#     client_id=client_id, \n",
    "#     director_node_fqdn=director_node_fqdn, \n",
    "#     director_port='50051',\n",
    "#     cert_chain=cert_chain, \n",
    "#     api_cert=api_certificate, \n",
    "#     api_private_key=api_private_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e22a51-219e-4c0d-83ea-0204f1779749",
   "metadata": {},
   "source": [
    "接続できたことを確認するため、Directorから現在接続されているコラボレーターの情報を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## 連合学習の開始"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce519d-4320-42ea-9b34-e50c2233081d",
   "metadata": {},
   "source": [
    "まずは学習の単位を表す概念である「実験（Experiment）」を作成する。実験にはFederationインスタンスとユニークな名前をセットする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'tinyimagenet_test_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537442de-486f-49f5-9e43-a9a47605e46a",
   "metadata": {},
   "source": [
    "その上で、実験のstartメソッドを呼び出す。引数としてこれまで定義してきたDataInterface、ModelInterface、TaskInterfaceをそれぞれセットする。rounds_to_trainはDirector⇔Collaboratorの一連のやり取りを何回実施するかを指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(\n",
    "    model_provider=model_interface, \n",
    "    task_keeper=task_interface,\n",
    "    data_loader=fed_dataset,\n",
    "    rounds_to_train=5,\n",
    "    opt_treatment='CONTINUE_GLOBAL',\n",
    "    override_config={'network.settings.agg_port': 50002}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc706d4-2761-469e-9e47-870437fb1523",
   "metadata": {},
   "source": [
    "## 学習の途中経過のモニター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83edd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
    "# fl_experiment.restore_experiment_state(model_interface)\n",
    "\n",
    "fl_experiment.stream_metrics(tensorboard_logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fb777-217b-458d-a805-9e03b740923f",
   "metadata": {},
   "source": [
    "## 学習後の結果の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fac272-427d-4db0-b6d4-edf824392851",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fl_experiment.get_best_model()\n",
    "torch.save(best_model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb9bfb-2fcc-4972-ad89-66adad4daafa",
   "metadata": {},
   "source": [
    "new_model = Net()\n",
    "new_model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0bb64-515a-4e2c-b139-79169179c0d8",
   "metadata": {},
   "source": [
    "## 実験データの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940ab65-b35e-416f-81ee-387d0961828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.remove_experiment_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
